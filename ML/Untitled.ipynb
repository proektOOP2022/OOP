{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c33b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c86a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf9642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d173fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da22174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c78ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter and density plots\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9bd8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d703ac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[contradictory-my-dear-watson,\n",
       " gan-getting-started,\n",
       " store-sales-time-series-forecasting,\n",
       " tpu-getting-started,\n",
       " digit-recognizer,\n",
       " titanic,\n",
       " house-prices-advanced-regression-techniques,\n",
       " connectx,\n",
       " nlp-getting-started,\n",
       " spaceship-titanic,\n",
       " facial-keypoints-detection,\n",
       " street-view-getting-started-with-julia,\n",
       " word2vec-nlp-tutorial,\n",
       " data-science-london-scikit-learn,\n",
       " just-the-basics-the-after-party,\n",
       " just-the-basics-strata-2013]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.competitions_list(category='gettingStarted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f6ca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[iamsouravbanerjee/world-population-dataset,\n",
       " pantanjali/unemployment-dataset,\n",
       " harshsingh2209/tesla-stock-pricing-20172022,\n",
       " thedevastator/airplane-crashes-and-fatalities,\n",
       " whenamancodes/student-performance,\n",
       " ariyoomotade/netflix-data-cleaning-analysis-and-visualization,\n",
       " whenamancodes/students-performance-in-exams,\n",
       " whenamancodes/violence-against-women-girls,\n",
       " whenamancodes/popular-movies-datasets-58000-movies,\n",
       " alexandrepetit881234/korean-demographics-20002022,\n",
       " whenamancodes/world-population-live-dataset,\n",
       " whenamancodes/netflix-prime-video-disney-hulu,\n",
       " thedevastator/mcdonalds-ice-cream-machines-broken-timeseries,\n",
       " deepcontractor/smoke-detection-dataset,\n",
       " thedevastator/weather-prediction,\n",
       " whenamancodes/data-science-fields-salary-categorization,\n",
       " moazzimalibhatti/co2-emission-by-countries-year-wise-17502022,\n",
       " sergylog/ab-test-data,\n",
       " advaypatil/youtube-statistics,\n",
       " nabilajahan/the-impact-of-electronic-gadget-uses]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.dataset_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0655ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[alvarobasily/road-damage,\n",
       " psycon/ukraine-mariupol-damage-assessment,\n",
       " prudhvignv/road-damage-classification-and-assessment,\n",
       " rounak041993/traffic-violations-in-maryland-county,\n",
       " nichaoku/gbaccident0516,\n",
       " mohammedkuheil/roaddamagegan,\n",
       " trolololo888/potholes-and-road-damage-with-annotations,\n",
       " hotsonhonet/hackerearths-fast-furious-and-insured-challenge,\n",
       " thaddeussegura/eminem-lyrics-from-all-albums,\n",
       " gan2gan/austin-bicycle-crashes-from-20102017,\n",
       " pachriisk/great-britain-road-accidents,\n",
       " dariasvasileva/hourly-weather-data-in-ireland-from-24-stations,\n",
       " ghalibahmed2022/road-damage-detection,\n",
       " ninaflirp/nashville-vehicle-collision-dataset]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.dataset_list(search=\"road damage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1287a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.dataset_download_files(\"prudhvignv/road-damage-classification-and-assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "411dedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile('road-damage-classification-and-assessment.zip')\n",
    "zf.extractall('./data/') #save files in selected folder\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f59b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
